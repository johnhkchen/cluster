# PERCI System Convergence Strategy

## ğŸ¯ Executive Summary

This document outlines how our current Kubernetes-based GitOps development environment converges with the practical Docker Compose + MQTT approach for deploying PERCI (Personal Cognitive Intelligence) across edge devices.

**Key Insight**: Our current foundation becomes PERCI's **orchestration and admin layer**, while edge devices run optimized Docker Compose stacks.

## ğŸ—ï¸ System Architecture Overview

### PERCI Component Distribution

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Pi 1: STT     â”‚  â”‚   Pi 2: NLP     â”‚  â”‚   Pi 3: TTS     â”‚  â”‚Pi 4: Orchestratorâ”‚
â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚
â”‚ â€¢ 3x Vosk       â”‚  â”‚ â€¢ Mini RWKV     â”‚  â”‚ â€¢ TTS Engine    â”‚  â”‚ â€¢ Admin UI      â”‚
â”‚ â€¢ SER Model     â”‚  â”‚ â€¢ NLP Recon     â”‚  â”‚ â€¢ Audio Out     â”‚  â”‚ â€¢ Watchdog      â”‚
â”‚ â€¢ Resemblyzer   â”‚  â”‚ â€¢ Preprocessing â”‚  â”‚ â€¢ Audio Proc    â”‚  â”‚ â€¢ Deployment    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                     â”‚                     â”‚                     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚                     â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚        Jetson Orin NX: Core AI         â”‚
                    â”‚                                         â”‚
                    â”‚ â€¢ RWKV "Consciousness" Core            â”‚
                    â”‚ â€¢ Main LLM (Inference)                 â”‚
                    â”‚ â€¢ Reflective LLM (Planning/Summary)    â”‚
                    â”‚ â€¢ Governor System (Safety/Monitoring)  â”‚
                    â”‚ â€¢ GPU-Accelerated Processing           â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Communication Backbone**: MQTT pub/sub for low-latency inter-component messaging

## ğŸ”„ Convergence Strategy

### Current State â†’ PERCI Orchestration

**What We Have Now:**
```yaml
Current Demo Stack:
  - FastAPI Backend: Health monitoring, device data simulation
  - Astro Frontend: Status dashboard, device management UI
  - Nginx Proxy: Service routing, rate limiting
  - GitOps/FluxCD: Automated deployment pipeline
  - Kubernetes: Local development environment
```

**How It Evolves:**
```yaml
PERCI Orchestration Layer:
  - FastAPI Backend â†’ PERCI Orchestrator API
    * Device health monitoring
    * Inter-service communication routing
    * Model loading/unloading management
    * Performance metrics collection
    
  - Astro Frontend â†’ PERCI Admin Interface
    * Real-time system monitoring
    * Log aggregation and viewing
    * Deployment management
    * Performance dashboards
    
  - Nginx Proxy â†’ Service Mesh Gateway
    * Load balancing across devices
    * Request routing to appropriate services
    * Rate limiting and protection
    
  - GitOps â†’ Configuration Management
    * Deploy Docker Compose files to devices
    * Manage model updates
    * Configuration synchronization
```

### Development vs Production Deployment

| Environment | Platform | Purpose | Deployment |
|-------------|----------|---------|------------|
| **Development** | Kind/K3s | Testing, development, integration | GitOps + Kubernetes |
| **Production Edge** | Docker Compose | Low-latency, reliable operation | GitOps â†’ Compose files |
| **Orchestration** | Pi 4 + Docker Compose | Admin, monitoring, watchdog | GitOps â†’ Compose files |

## ğŸ“‹ Implementation Phases

### Phase 1: Foundation Extension (Current â†’ PERCI Base)

**Goal**: Transform demo-hello into PERCI orchestrator

**Changes to Current Stack:**

1. **FastAPI Backend Extensions**
```python
# Current: Simple health check + mock devices
# Future: PERCI orchestration API

@app.get("/devices")  # Device discovery and health
@app.post("/deploy/{device_id}")  # Deploy services to devices
@app.get("/metrics/{service}")  # Service performance metrics
@app.post("/models/load")  # Model management
@app.get("/logs/{device_id}")  # Log aggregation

# MQTT Integration
@app.post("/mqtt/publish")  # Send commands via MQTT
@app.get("/mqtt/status")  # MQTT broker health
```

2. **Astro Frontend Extensions**
```typescript
// Current: Simple device status display
// Future: PERCI admin dashboard

- Real-time device health monitoring
- Service logs viewing (STT, NLP, LLM, TTS)
- Performance metrics dashboards
- Deployment management interface
- MQTT message monitoring
- Model loading status
```

3. **MQTT Backbone Integration**
```yaml
# Add to current stack:
MQTT Broker: 
  - Eclipse Mosquitto container
  - Topic structure for PERCI communication
  - Security configuration

Topic Structure:
  - perci/stt/audio â†’ Raw audio to STT
  - perci/stt/text â†’ Transcribed text
  - perci/nlp/processed â†’ Processed/reconstructed text  
  - perci/core/input â†’ Input to consciousness core
  - perci/llm/response â†’ LLM response
  - perci/tts/audio â†’ Audio output
  - perci/admin/* â†’ Administrative commands
```

### Phase 2: Device-Specific Docker Compose

**Goal**: Create production deployment configurations

**Directory Structure:**
```
apps/
â”œâ”€â”€ perci-orchestrator/     # Current demo-hello evolved
â”‚   â”œâ”€â”€ backend/           # FastAPI orchestrator
â”‚   â”œâ”€â”€ frontend/          # Astro admin interface  
â”‚   â””â”€â”€ k8s/              # Development deployment
â”œâ”€â”€ device-configs/        # Production edge configs
â”‚   â”œâ”€â”€ pi-stt/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”‚   â”œâ”€â”€ vosk-config/
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”œâ”€â”€ pi-nlp/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”‚   â”œâ”€â”€ rwkv-config/
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”œâ”€â”€ pi-tts/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”‚   â””â”€â”€ tts-config/
â”‚   â”œâ”€â”€ pi-orchestrator/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml  # Admin stack
â”‚   â”‚   â””â”€â”€ nginx.conf
â”‚   â””â”€â”€ jetson-core/
â”‚       â”œâ”€â”€ docker-compose.yml
â”‚       â”œâ”€â”€ gpu-config/
â”‚       â””â”€â”€ models/
â””â”€â”€ mqtt-backbone/
    â”œâ”€â”€ mosquitto.conf
    â””â”€â”€ security/
```

**Example Pi STT Docker Compose:**
```yaml
# device-configs/pi-stt/docker-compose.yml
version: '3.8'
services:
  vosk-en:
    image: alphacep/kaldi-en:latest
    ports:
      - "2700:2700"
    volumes:
      - ./models:/opt/vosk-model

  vosk-multilang:
    image: alphacep/kaldi-multilang:latest
    ports:
      - "2701:2700"
    volumes:
      - ./models:/opt/vosk-model

  ser-model:
    build: ./ser-container
    depends_on:
      - vosk-en
    environment:
      - VOSK_SERVER=vosk-en:2700

  resemblyzer:
    build: ./resemblyzer-container
    volumes:
      - ./speaker-profiles:/app/profiles

  stt-coordinator:
    build: ./coordinator
    depends_on:
      - vosk-en
      - vosk-multilang
      - ser-model
      - resemblyzer
    environment:
      - MQTT_BROKER=pi-orchestrator.local:1883
    ports:
      - "8080:8080"

  watchdog:
    build: ./watchdog
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    restart: unless-stopped
```

### Phase 3: GitOps Integration

**Goal**: Unified deployment pipeline for both K8s dev and Compose prod

**GitOps Structure:**
```
clusters/
â”œâ”€â”€ dev/                   # Current K8s development
â”‚   â””â”€â”€ perci-orchestrator.yaml
â”œâ”€â”€ production/            # Edge device management
â”‚   â”œâ”€â”€ pi-stt.yaml       # FluxCD config for Pi STT
â”‚   â”œâ”€â”€ pi-nlp.yaml
â”‚   â”œâ”€â”€ pi-tts.yaml
â”‚   â”œâ”€â”€ pi-orchestrator.yaml
â”‚   â””â”€â”€ jetson-core.yaml
â””â”€â”€ shared/
    â”œâ”€â”€ mqtt-config/
    â””â”€â”€ security/
```

**FluxCD Kustomizations for Edge Devices:**
```yaml
# clusters/production/pi-stt.yaml
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: pi-stt
  namespace: flux-system
spec:
  interval: 5m0s
  path: ./device-configs/pi-stt
  prune: true
  sourceRef:
    kind: GitRepository
    name: flux-system
  postBuild:
    substitute:
      DEVICE_ID: "pi-stt-001"
      MQTT_BROKER: "pi-orchestrator.local"
  healthChecks:
    - apiVersion: v1
      kind: Service
      name: stt-coordinator
      namespace: default
```

## ğŸ”§ Technical Implementation Details

### MQTT Message Flow

```
Audio Input â†’ [Pi 1: STT] â†’ perci/stt/text
                    â†“
perci/nlp/input â† [Pi 2: NLP] â† perci/stt/text
                    â†“
perci/core/input â† [Jetson: Core] â† perci/nlp/processed
                    â†“
perci/llm/response â†’ [Jetson: LLM] â†’ perci/tts/input
                    â†“
perci/tts/audio â† [Pi 3: TTS] â† perci/tts/input
                    â†“
Audio Output
```

**Administrative Flow:**
```
[Pi 4: Admin] â†’ perci/admin/deploy â†’ All devices
[Pi 4: Admin] â† perci/admin/status â† All devices
[Pi 4: Admin] â†’ perci/admin/logs â†’ Centralized logging
```

### Service Discovery & Health Monitoring

**Each device publishes:**
```json
{
  "device_id": "pi-stt-001",
  "services": ["vosk-en", "vosk-multilang", "ser-model"],
  "health": {
    "cpu_usage": 45.2,
    "memory_usage": 62.1,
    "disk_usage": 23.4,
    "gpu_usage": null
  },
  "last_seen": "2025-01-04T12:34:56Z"
}
```

**Orchestrator tracks:**
- Service availability across all devices
- Performance metrics and bottlenecks
- Message flow latency
- Error rates and failure patterns

### Configuration Management

**Shared Configuration:**
```yaml
# Managed via GitOps, deployed to all devices
mqtt:
  broker: "pi-orchestrator.local:1883"
  topics:
    stt_output: "perci/stt/text"
    nlp_input: "perci/nlp/input"
    # ... etc

models:
  stt:
    vosk_model_path: "/opt/models/vosk-model-en-us"
    ser_model_path: "/opt/models/ser-model"
  nlp:
    rwkv_model_path: "/opt/models/rwkv-mini"
  # ... etc

security:
  mqtt_username: "${MQTT_USER}"
  mqtt_password: "${MQTT_PASS}"
  device_certificates: "/opt/certs/"
```

### Deployment Pipeline

1. **Development**: Code changes â†’ Git â†’ FluxCD â†’ K8s development cluster
2. **Testing**: Integration tests in K8s environment
3. **Production**: Git â†’ FluxCD â†’ Docker Compose files deployed to edge devices
4. **Monitoring**: All devices report back to orchestrator

## ğŸš€ Migration Path

### Week 1-2: Foundation Extension
- [ ] Extend FastAPI backend with PERCI orchestration endpoints
- [ ] Add MQTT broker to current stack
- [ ] Update Astro frontend for device monitoring
- [ ] Test MQTT communication in K8s environment

### Week 3-4: Docker Compose Creation
- [ ] Create Docker Compose files for each device type
- [ ] Build container images for PERCI components
- [ ] Test Docker Compose stacks locally
- [ ] Implement watchdog services

### Week 5-6: GitOps Integration
- [ ] Extend GitOps to manage Docker Compose deployments
- [ ] Create device-specific FluxCD configurations
- [ ] Implement automated deployment pipeline
- [ ] Test full GitOps â†’ Docker Compose workflow

### Week 7-8: Production Deployment
- [ ] Deploy to actual Pi hardware
- [ ] Deploy to Jetson Orin NX
- [ ] Performance optimization and tuning
- [ ] Production monitoring and alerting

## ğŸ¯ Success Metrics

**Development Environment:**
- [ ] PERCI components run successfully in K8s
- [ ] MQTT communication works end-to-end
- [ ] Admin interface provides full visibility
- [ ] GitOps pipeline deploys changes automatically

**Production Environment:**
- [ ] All Pi devices run their services reliably
- [ ] Jetson core processes LLM requests efficiently
- [ ] MQTT latency < 50ms for critical paths
- [ ] System recovers automatically from component failures
- [ ] Admin interface provides real-time monitoring

## ğŸ”— Integration with Colleague's Approach

This convergence strategy directly implements your colleague's recommended approach:

**Phase 1 Alignment:**
- âœ… Docker Compose on each device (production deployment)
- âœ… MQTT backbone for pub/sub communication
- âœ… Admin UI for monitoring (your Astro frontend)
- âœ… Watchdog outside Kubernetes (per-device Docker Compose)

**Phase 2+ Readiness:**
- ğŸ¯ Easy transition from Docker Compose â†’ K3s (same containers)
- ğŸ¯ Service mesh patterns already established (nginx proxy)
- ğŸ¯ Monitoring infrastructure ready for Prometheus/Grafana
- ğŸ¯ Security patterns established for secrets management

**Key Insight**: Your Kubernetes development environment becomes the **testing and integration platform**, while production uses the simpler, more reliable Docker Compose approach your colleague recommends. Best of both worlds!